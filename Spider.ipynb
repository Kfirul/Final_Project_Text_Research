{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ed2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "def parse_word(response):\n",
    "    word = response.meta['word']\n",
    "    \n",
    "    # Extracting lexicons\n",
    "    word['lexicon_0'] = response.xpath('//body/br[2]/following-sibling::text()').get()\n",
    "    if word['lexicon_0'] and word['lexicon_0'].strip() == '':\n",
    "        word['lexicon_0'] = response.xpath('//body/br[3]/following-sibling::text()').get()\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        lex = response.xpath(f'//body/hr[{i}]/following-sibling::text()').get()\n",
    "        if lex and lex.strip() != '':\n",
    "            word[f'lexicon_{i}'] = lex.strip()\n",
    "        else:\n",
    "            word[f'lexicon_{i}'] = None\n",
    "\n",
    "    # Extracting multiple word meanings\n",
    "    meanings = response.xpath('//span[@class=\"mgP\"]/text()').getall()\n",
    "    for i, meaning in enumerate(meanings):\n",
    "        # Limit to up to 4 meanings to avoid excessive columns\n",
    "        if i < 4:\n",
    "            word[f'meaning_{i}'] = meaning.strip()\n",
    "    \n",
    "    # Fill any remaining meaning columns with None\n",
    "    for i in range(len(meanings), 4):\n",
    "        word[f'meaning_{i}'] = None\n",
    "\n",
    "    yield word\n",
    "\n",
    "class CalWordSpider(scrapy.Spider):\n",
    "    name = 'cal'\n",
    "    # replace url\n",
    "    start_urls = [\n",
    "        'https://cal.huc.edu/get_a_chapter.php?file=71022'\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for el in response.css('tr > td:nth-child(2) > a'):\n",
    "            word = {\n",
    "                'text': el.css('::text').get(),\n",
    "                'url': el.xpath('@href').get()\n",
    "            }\n",
    "            yield scrapy.Request(\n",
    "                url=f\"https://cal.huc.edu/{word['url']}\",\n",
    "                meta={'word': word},\n",
    "                callback=parse_word\n",
    "            )\n",
    "\n",
    "# Run the spider\n",
    "process = CrawlerProcess(settings={\n",
    "    'FEEDS': {\n",
    "        'Masekhet_bb.json': {\n",
    "            'format': 'json',\n",
    "            'overwrite': True\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "process.crawl(CalWordSpider)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305e065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
